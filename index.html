<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yulin Yang</title>
  
  <meta name="author" content="Yulin Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon11.png">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yulin Yang</name>
              </p>
              <p>I am currently a Machine Learing Engineer at Apple.
                My research focuses on robot navigation and state estimation.
              </p>
              <p>
                I defended my Ph.D. in <a href="https://sites.udel.edu/robot/">Robot Perception and Navigation Group</a> at <a href="https://www.udel.edu/">University of Delaware</a> in Oct. 2021, advised by <a href="https://udel.edu/~ghuang/">Prof. Guoquan (Paul) Huang</a>.
                I received <a href="https://www.mathsci.udel.edu/educational-programs/the-graduate-program">Master of Science degree in Mathematics</a> from University of Delaware in 2020,
                Master of Engineering degree in Mechanical Engineering from <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University</a> in 2012,
                and Bachelor of Engineering degree in Mechanical Engineering from <a href="https://en.sdu.edu.cn/">Shandong University</a> in 2009.
                I was a recipient of the <a href="http://www.education.udel.edu/grad-awards/">University Doctoral Fellowship Award (2019-2020)</a> at University of Delaware.
                I have also completed internship programs at <a href="https://tech.fb.com/ar-vr/">Facebook Reality Lab</a> and
                <a href="https://www.bosch.us/our-company/bosch-in-the-usa/sunnyvale/">Bosch Research Institute</a>, respectively.
<!--                <br>-->
<!--                <br>-->
<!--                Before joining Udel, I was an R&D engineer for <a href="https://www.siemens-energy.com/global/en/offerings/power-transmission.html">SIEMENS</a> in Shanghai. I got Master in Engineering from <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University</a>  and Bachelor in Engineering from <a href="https://en.sdu.edu.cn/">Shandong University</a>.-->
              </p>
              <p style="text-align:center">
                <a href="mailto:yangyulin1@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Yulin_Yang_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=zToUVcwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.researchgate.net/profile/Yulin-Yang-4">Research Gate</a> &nbsp/&nbsp
                <a href="https://github.com/yangyulin/">GitHub</a>  &nbsp/&nbsp
                <a href="https://twitter.com/YulinYang4">Twitter</a> &nbsp/&nbsp
                <a href="http://udel.edu/~yuyang/">Homepage@Udel</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yulin_yang.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/yulin_yang.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests are within the areas of robot navigation, simultaneous localization and mapping (SLAM), computer vision, optimization, and multi-sensor fusion,
                with a concentration on enabling robots to perceive the world through fusing multi-modality information from different sensors (visual cameras, IMUs, sonar, wheel encoder, 2D/3D LiDAR, GPS and so forth).
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Publications</heading>
            <p>
              Please find below a complete list of my publications with representative papers <span class="highlight">highlighted</span>.
            </p>
          </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/2023_mvis.png" alt="secure" width="300" height="160">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2023_arxiv.pdf">
              <papertitle>Multi-Visual-Inertial System: Analysis,Calibration and Estimation</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>arXiv</em>, 2023
            <br>
            <a href="data/Yang2023arXiv.bib">bibtex</a>
            <br>
            <p></p>
            <p>
              Multi-visual-inertial system with full-parameter calibration
              <br>
              IMU/camera intrinsics, IMU-IMU/camera spatial-temporal and RS calibration
              <br>
              Observability analysis and degenerate motion identification for MVIS with full calibration
              <br>
              Extensive simulations on 3 typical trajectories
              <br>
              Extensive evaluation with a self-made device regarding to Kalibr
              <br>
              Datasets are open-sourced in <a href="https://openmvis.com/">openmvis.com</a>
            </p>
          </td>
        </tr>





        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/ijrr_virig.png" alt="secure" width="300" height="240">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2023_tro_full_calib.pdf">
              <papertitle>Online Self-Calibration for Visual-Inertial Navigation Systems: Models, Analysis and Degeneracy</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://xingxingzuo.github.io/">Xingxing Zuo</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE Transactions On Robotics</em>, 2023
            <br>
            <a href="data/Yang2022arXiv.bib">bibtex</a>
            /
            <a href="https://youtu.be/PoIPO48ZikM">video</a>
            <br>
            <br>
            <a href="papers/2022_tr_fullcalib.pdf">Supplementary Materials: Online Self-Calibration for Visual-Inertial Navigation Systems: Models, Analysis and Degeneracy</a>
            <br>
            <p></p>
            <p>
              Monocular VINS with full-parameter online self-calibration
              <br>
              IMU/camera intrinsics, IMU-camera spatial-temporal and RS calibration
              <br>
              Observability analysis for monocular VINS with full calibration
              <br>
              Comprehensive degenerate motion identification for IMU/camera intrinsics
              <br>
              Extensive simulations to verify different IMU intrinsic models
              <br>
              Extensive real-world experiments on TUM visual-inertial rolling-shutter datasets
              <br>
              Extensive evaluation with regarding to Kalibr
              <br>
              IMU intrinsic calibration code is released in OpenVINS
            </p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/2023_gnc.png" alt="secure" width="300" height="250">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2023_gnc.pdf">
              <papertitle>Resilient Ground Vehicle Autonomous Navigation in GPS-Denied Environment</papertitle>
            </a>
            <br>Kleio Baxevani, Indrajeet Yadav, Yulin Yang, Michael Sebok, Herbert G. Tanner and Guoquan Huang
            <a href="https://udel.edu">Kleio Baxevani</a>,
            <a href="https://udel.edu">Indrajeet Yadav</a>,
            <strong>Yulin Yang*</strong>,
            <a href="https://udel.edu">Michael Sebok</a>,
            <a href="http://research.me.udel.edu/~btanner/index.html">Herbert G. Tanner</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>Guidance, Navigation and Control</em>, 2023
            <br>
            <a href="data/Kleo2023GNC.bib">bibtex</a>
            <br>
            <p></p>
            <p>
              Autonomous path planning and sensor calibration for unmanned ground vehicle.
            </p>
          </td>
        </tr>




        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/2023_iros_mav.png" alt="secure" width="300" height="100">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2022_iros_mav.pdf">
              <papertitle>Visual-inertial-aided online mav system identification</papertitle>
            </a>
            <br>
            <a href="https://chuchuchen.net/">Chuchu Chen*</a>,
            <strong>Yulin Yang*</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://woosik.synology.me/wordpress/">Woosik Lee</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2022
            <br>
            <a href="data/Chen2022IROS.bib">bibtex</a>
            <br>
            <br>
            <a href="papers/rpng_tr_2022_mav.pdf">Supplementary Materials: Visual-Inertial-Aided Online MAV System Identification</a>
            <br>
            <p></p>
            <p>
              Tightly coupled MAV dynamic system with VINS.
            </p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/2022_icra_gnss.png" alt="secure" width="300" height="280">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2022_icra_fej2.pdf">
              <papertitle>Tightly-coupled GNSS-aided visual-inertial localization</papertitle>
            </a>
            <br>
            <a href="https://woosik.synology.me/wordpress/">Woosik Lee</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2022
            <br>
            <a href="data/Lee2022ICRA.bib">bibtex</a>
            <br>
            <p></p>
            <p>
             VINS tightly coupled with GNSS measurements.

            </p>
          </td>
        </tr>





        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/2022_fej2.png" alt="secure" width="300" height="150">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2022_icra_fej2.pdf">
              <papertitle>FEJ2: A consistent visual-inertial state estimator design</papertitle>
            </a>
            <br>
            <a href="https://chuchuchen.net/">Chuchu Chen</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2022
            <br>
            <a href="data/Chen2022ICRA.bib">bibtex</a>
            <br>
            <br>
            <a href="papers/rpng_tr_2022_fej2.pdf">Technical Report: FEJ2: A Consistent Visual-Inertial State Estimator Design</a>
            <br>
            <p></p>
            <p>
              Improve FEJ to compensate the lieanrization errors.
            </p>
          </td>
        </tr>








        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/ral_dri_2022.png" alt="secure" width="300" height="170">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2022_RAL_DRI.pdf">
              <papertitle>Decoupled Right Invariant Error States for Consistent Visual-Inertial Navigation</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>,
            <a href="https://sites.udel.edu/robot/people/">Chuchu Chen</a>,
            <a href="https://woosik.synology.me/wordpress/">Woosik Lee</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE Robotics and Automation Letters (RAL)</em>, 2022
            <br>
            <a href="data/Yang2022RAL.bib">bibtex</a>
            /
            <a href="papers/2022_RAL_DRI.mp4">video</a>
            /
            <a href="papers/2021_supp_DRI.pdf">Supplementary Materials</a>
            <br>
            <br>
            <a href="papers/2021_supp_DRI.pdf">Supplementary Materials: Decoupled Right Invariant Error States for Consistent Visual-Inertial Navigation</a>
            <br>
            <p></p>
            <p>
              Observability analysis and computation analysis for RI-VINS
              <br>
              Decoupled Right Invariant (DRI) based consistent algorithms (DRI-FEJ and DRI-SW)
              <br>
              Comprehensive evaluations for DRI-FEJ, DRI-SW, DLI-FEJ, FEJ, and standard EKF based VINS
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/icalib_vins_worshop.png" alt="secure" width="300" height="130">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2021_vinsworkshop_iCalib.pdf">
              <papertitle>iCalib: Inertial Aided Multi-Sensor Calibration</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>,
            <a href="https://woosik.synology.me/wordpress/">Woosik Lee</a>,
            <a href="https://sites.udel.edu/robot/people/">Philip Osteen</a>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://xingxingzuo.github.io/">Xingxing Zuo</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>VINS Workshop@ICRA</em>, 2021
            <br>
            <a href="data/Yang2021VINSws.bib">bibtex</a>
            /
            <a href="https://youtu.be/0upriLXGEC0">video</a>
            /
            <a href="papers/ICRA_2021_workshop_icalib_slides.pdf">slides</a>
            <br>
            <p></p>
            <p>
              Inertial aided multi-sensor calibration with spatial-temporal and intrinsic calibration.
              <br>
              Observability analysis and degenerate motion identification.
              <br>
              IMU, multi-cameras, LiDAR and wheel encoder.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/2021_icra_mins.png" alt="secure" width="300" height="180">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2021_icra_mins.pdf">
              <papertitle>Efficient Multi-Sensor Aided Inertial Navigation with Online Calibration</papertitle>
            </a>
            <br>
            <a href="https://woosik.synology.me/wordpress/">Woosik Lee</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2021
            <br>
            <a href="data/Lee2021ICRA.bib">bibtex</a> /
            <a href="https://youtu.be/rV50nLJ6Mt0">video</a>
            <br>
            <p></p>
            <p>
              MINS: a tightly-coupled IMU/CAM/LiDAR/Wheel/GPS navigation system
              <br>
              Plane patch-based efficient feature tracking with 10hz 64 channel LiDAR.
              <br>
              Intensive evaluations with realistic simulations and urban driving real world datasets.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/2021_icra_cvio.png" alt="secure" width="300" height="250">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2021_icra_cvio.pdf">
              <papertitle>Cooperative Visual-Inertial Odometry</papertitle>
            </a>
            <br>
            <a href="https://www.linkedin.com/in/pengxiang-zhu-9152b019b/">Pengxiang Zhu</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://intra.ece.ucr.edu/~ren/">Wei Ren</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2021
            <br>
            <a href="data/Zhu2021ICRA_cvio.bib">bibtex</a> /
            <a href="https://youtu.be/bJJJQCOThSY">video</a>
            <br>
            <p></p>
            <p>
              Fully distributed cooperative (DISC)-VIO based on covariance intersection.
              <br>
              Centralized-equivalent cooperative (CEC)-VIO.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/iros2020_lic.png" alt="secure" width="300" height="180">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2020_iros_lic2.pdf">
              <papertitle>LIC-Fusion 2.0: LiDAR-Inertial-Camera Odometry with Sliding-Window Plane-Feature Tracking</papertitle>
            </a>
            <br>
            <a href="https://xingxingzuo.github.io/">Xingxing Zuo</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://april.zju.edu.cn/team/jiajun-lv/">Jiajun Lv</a>,
            <a href="https://april.zju.edu.cn/team/dr-yong-liu/">Yong Liu</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2020
            <br>
            <a href="data/Zuo2020IROS.bib">bibtex</a> /
            <a href="https://youtu.be/gNh_CEEfFts">video</a>
            <br>
            <p></p>
            <p>
              Sliding window based Lidar plane tracking.
              <br>
              LiDAR-Inertial-Camera fusion.
              <br>
              Intensive evaluations with Monte-Carlo simulations and real world datasets.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/iros2020_viwo.png" alt="secure" width="300" height="210">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2020_iros_viwo.pdf">
              <papertitle>Visual-inertial-wheel odometry with online calibration</papertitle>
            </a>
            <br>
            <a href="https://woosik.synology.me/wordpress/">Woosik Lee</a>,
            <a href="https://sites.udel.edu/robot/people/">Kevin Eckenhoff</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2020
            <br>
            <a href="data/Lee2020IROS.bib">bibtex</a> /
            <a href="https://youtu.be/4DH-J5OtjLc">video</a>
            <br>
            <p></p>
            <p>
              Tightly-coupled Visual-inertial-wheel odometry.
              <br>
              Observability analysis and degenerate motion identification.
              <br>
              Intensive evaluations with Monte-Carlo simulations and real world datasets.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/iros2020_geek.png" alt="secure" width="300" height="150">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2020_iros_geek.pdf">
              <papertitle>Versatile 3D Multi-Sensor Fusion for Lightweight 2D Localization</papertitle>
            </a>
            <br>
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="http://udel.edu/~nmerrill/">Nate Merrill</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://sites.udel.edu/robot/people/">Chuchu Chen</a>,
            <a href="https://woosik.synology.me/wordpress/">Woosik Lee</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2020
            <br>
            <a href="data/Lee2020IROS.bib">bibtex</a> /
            <a href="https://youtu.be/sxq75Cgeb48">video</a>
            <br>
            <p></p>
            <p>
              Exploit 2D line for improved loop detection for occupancy grid mapping.
              <br>
              Design EKF framework to fuse inertial, odometry and 2D LiDAR.
              <br>
              Intensive evaluations with Monte-Carlo simulations and real world datasets.
            </p>
          </td>
        </tr>


        <tr  bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/rss2020_rpng.png" alt="secure" width="300" height="180">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2020_rss.pdf">
              <papertitle>Online IMU Intrinsic Calibration: Is It Necessary?</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://scholar.google.com/citations?user=CePv8agAAAAJ&hl=zh-CN">Xingxing Zuo</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>Robotics: Science and Systems (RSS)</em>, 2020
            <br>
            <a href="data/Yang2020RSS.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=k2JPxXnE78Q">video</a> /
            <a href="https://www.youtube.com/watch?v=uf367hP6s3M">video</a> /
            <a href="https://youtu.be/tGF867Rw1M8">video</a>
            <br>
            <br>
            <a href="papers/2020_RSS_appendix.pdf">Supplementary Materials: Online IMU Intrinsic Calibration: Is It Necessary?</a>
            <br>
            <p></p>
            <p>
              Mono-VINS with online IMU intrinsic calibration.
              <br>
              Observability analysis and degenerate motion identification for IMU intrinsics.
              <br>
              Intensive evaluations with Monte-Carlo simulations and real world datasets.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/jfr2020.jpg" alt="secure" width="300" height="130">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2020_jfr.pdf">
              <papertitle>Multimodal localization: Stereo over LiDAR map</papertitle>
            </a>
            <br>
            <a href="https://xingxingzuo.github.io/">Xingxing Zuo</a>,
            <a href="https://april.zju.edu.cn/team/wenlong-ye/">Wenlong Ye</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://april.zju.edu.cn/team/renjie-zheng/">Renjie Zheng</a>,
            <a href="https://profiles.uts.edu.au/Teresa.VidalCalleja">Teresa Vidal‐Calleja</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>,
            <a href="https://april.zju.edu.cn/team/dr-yong-liu/">Yong Liu</a>,
            <br>
            <em>Journal of Field Robotics (JFR)</em>, 2020
            <br>
            <a href="data/Zuo2020JFR.bib">bibtex</a>
            <br>
            <p></p>
            <p>
              Efficient visual odometry by leveraging prior LiDRA map.
              <br>
              Leverage ProW-NDT for semidense visual map and prior LiDAR map registration.
              <br>
              Intensive evaluations with simulations and real world datasets.
            </p>
          </td>
        </tr>




        <tr  bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/icra2020_aci.png" alt="secure" width="300" height="200">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2020_icra_aci.pdf">
              <papertitle>Analytic Combined IMU Integration (ACI^2) For Visual Inertial Navigation</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>,
            <a href="https://www.benzun.xyz/">Benzun Pious Wisely Babu</a>,
            <a href="https://sites.udel.edu/robot/people/">Chuchu Chen</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>,
            <a href="https://sites.google.com/site/liurenshomepage/">Liu Ren</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020
            <br>
            <a href="data/Yang2020ICRA.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=HruIZjulMDk">video</a> /
            <a href="https://scholar.google.com/scholar?oi=bibs&cluster=9201331260757174263&btnI=1&hl=en">tech report</a>
            <br>
            <br>
            <a href="papers/supplementary_aci.pdf">Supplementary Materials: Analytic Combined IMU Integration (ACI^2) For Visual Inertial Navigation</a>
            <br>
            <p></p>
            <p>
              Modularized and analytic derived IMU integration algorithm.
              <br>
              Graph-based VINS with IMU-CAM time offset calibration.
              <br>
              Evaluations with Monte-Carlo simulations and real world experiments.
            </p>
          </td>
        </tr>


        <tr  bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/icra2020_ov.png" alt="secure" width="300" height="150">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2020_icra_ov.pdf">
              <papertitle>Openvins: A research platform for visual-inertial estimation</papertitle>
            </a>
            <br>
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://sites.udel.edu/robot/people/">Kevin Eckenhoff</a>,
            <a href="https://woosik.synology.me/wordpress/">Woosik Lee</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020
            <br>
            <a href="data/Geneva2020ICRA.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=CIwNwmFroLI">video</a> /
            <a href="https://www.youtube.com/watch?v=MCzTF9ye2zw">video</a> /
            <a href="https://www.youtube.com/watch?v=Lc7VQHngSuQ">video</a> /
            <a href="https://www.youtube.com/watch?v=KCX51GvYGss">video</a> /
            <a href="https://github.com/rpng/open_vins">code</a> /
            <a href="https://docs.openvins.com/">doc</a>
            <br>
            <p></p>
            <p>
              A research platform for visual-inertial estimation.
              <br>
              IMU-CAM spatial-temporal calibration and cam intrinsic calibration.
              <br>
              Intensive evaluations with Monte-Carlo simulations and real world datasets.
            </p>
          </td>
        </tr>


        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/iros2019.png" alt="secure" width="300" height="100">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2019_iros_vinpl.pdf">
              <papertitle>Visual-Inertial Odometry with Point and Line Features</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://sites.udel.edu/robot/people/">Kevin Eckenhoff</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2019
            <br>
            <a href="data/Yang2019IROS.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=tEd2HCTNNmI">video</a>
            <br>
            <p></p>
            <p>
              Tightly-coupled VINS with point and line features.
              <br>
              Two line triangulation algorithms.
              <br>
              Degenerate motion analysis for line triangulation.
            </p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/ral2019_mapconstraints.png" alt="secure" width="300" height="150">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2019_iros_ral_map_resue.pdf">
              <papertitle>Visual-Inertial Localization With Prior LiDAR Map Constraints</papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com/citations?user=CePv8agAAAAJ&hl=zh-CN">Xingxing Zuo</a>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <strong>Yulin Yang</strong>,
            <a href="https://april.zju.edu.cn/team/wenlong-ye/">Wenlong Ye</a>,
            <a href="https://april.zju.edu.cn/team/dr-yong-liu/">Yong Liu</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE Robotics and Automation Letters (RAL)</em>, 2019
            <br>
            <a href="data/Zuo2019RAL.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=76fXMVhhX4E">video</a>
            <br>
            <p></p>
            <p>
              A tightly-coupled VI system using prior LiDAR map constraints through MSCKF update.
              <br>
              Intensive simulations and real world experiments.
            </p>
          </td>
        </tr>


        <tr  bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/tro2019.png" alt="secure" width="300" height="300">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2019_tro.pdf">
              <papertitle>Observability Analysis of Aided INS with Heterogeneous Features of Points, Lines and Planes</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE Transactions on Robotics (TRO)</em>, 2019
            <br>
            <a href="data/Yang2019TRO.bib">bibtex</a>
            <br>
            <p></p>
            <p>
              Unified feature representation (CP/Quaternion) for point/line/plane.
              <br>
              Complete observability analysis for VINS with point/line/plane
              <br>
              Intensive simulations for VINS with point/line/plane
            </p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/icra2019_vinpp.png" alt="secure" width="300" height="150">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2019_icra_vinpp.pdf">
              <papertitle>Tightly-coupled aided inertial navigation with point and plane features</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>, <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://scholar.google.com/citations?user=CePv8agAAAAJ&hl=zh-CN">Xingxing Zuo</a>,
            <a href="https://sites.udel.edu/robot/people/">Kevin Eckenhoff</a>,
            <a href="https://april.zju.edu.cn/team/dr-yong-liu/">Yong Liu</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2019
            <br>
            <a href="data/Yang2019ICRA_vinpp.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=QvmbeowSJeI">video</a>
            <br>
            <p></p>
            <p>
              Tightly-coupled visual-inertial system with point and plane features.
              <br>
              Tested point-on-plane constraints.
              <br>
              Both simulations and real world experiments.
            </p>
          </td>
        </tr>






        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/icra2019_unified.png" alt="secure" width="300" height="120">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2019_icra_unified.pdf">
              <papertitle>Aided Inertial Navigation: Unified Feature Representations and Observability Analysis</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2019
            <br>
            <a href="data/Yang2019ICRA_unified.bib">bibtex</a>
            <br>
            <p></p>
            <p>
              Unified feature representation (CP/Quaternion) for point/line/plane.
              <br>
              Observability analysis for VINS with point/line/plane
            </p>
          </td>
        </tr>


        <tr  bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/ral2019_calib.png" alt="secure" width="300" height="150">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2019_icra_degenerate.pdf">
              <papertitle>Degenerate Motion Analysis for Aided INS with Online Spatial and Temporal Sensor Calibration</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>,
            <a href="https://sites.udel.edu/robot/people/">Kevin Eckenhoff</a>,
            <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE Robotics and Automation Letters (RAL)</em>, 2019
            <br>
            <a href="data/Yang2019RAL.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=fjjDm50LcWs">video</a>
            <br>
            <p></p>
            <p>
              Observability analysis for VINS with spatial-temporal calibration.
              <br>
              4 degenerate motion profiles for IMU-CAM calibration.
              <br>
              Intensive simulations and real world experiments.
            </p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/ral2019_target.png" alt="secure" width="300" height="150">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2019_icra_target.pdf">
              <papertitle>Tightly-Coupled Visual-Inertial Localization and 3D Rigid-Body Target Tracking</papertitle>
            </a>
            <br>
            <a href="https://sites.udel.edu/robot/people/">Kevin Eckenhoff</a>, <strong>Yulin Yang</strong>,
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE Robotics and Automation Letters (RAL)</em>, 2019
            <br>
            <a href="data/Eckenhoff2019RAL.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=oq0bC7jBpjM">video</a>
            <br>
            <p></p>
            <p>Tightly-coupled visual-inertial target tracking.
              <br>
              Target represented as 3D rigid body.
              <br>
              Intensive simulations and real world experiments.
            </p>
          </td>
        </tr>





        <tr  bgcolor="#ffffd0">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/iros2018.png" alt="secure" width="300" height="100">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2018_iros_lips.pdf">
              <papertitle>LIPS: LiDAR-Inertial 3D Plane SLAM</papertitle>
            </a>
            <br>
            <a href="https://udel.edu/~pgeneva/">Patrick Geneva</a>, <a href="https://sites.udel.edu/robot/people/">Kevin Eckenhoff</a>,
            <strong>Yulin Yang</strong>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2018
            <br>
            <a href="data/Geneva2018IROS.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=O5XffJHLaRA">video</a> /
            <a href="https://github.com/rpng/lips">code</a>
            <br>
            <p></p>
            <p>Closest Point (CP) representation for 3D plane.
              <br>
              Open source code for 3D LiDAR simulator.
              <br>
              LiDAR based 3D plane SLAM (LIPS).
            </p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/icra2018.png" alt="secure" width="300" height="100">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2018_icra_plp.pdf">
              <papertitle>Aided Inertial Navigation with Geometric Features: Observability Analysis</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2018
            <br>
            <a href="data/Yang2018ICRA.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=oTIz2mKSzcw">video</a> /
            <a href="https://www.youtube.com/watch?v=lmxnwuT4oZI">video</a> /
            <a href="https://www.youtube.com/watch?v=_duPHJJRAxc">video</a>
            <br>
            <p></p>
            <p>Observability analysis for aided INS with point/line/plane.
              <br>
              5 dof nullspace for VINS with one line and 7 dof nullspace with one plane.
              <br>
              VINS simulation with point/line/plane.
            </p>
          </td>
        </tr>



        <tr >
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/isrr2017.png" alt="secure" width="300" height="240">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2020_secure.pdf">
              <papertitle>Map-Based Localization Under Adversarial Attacks</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>The 18th International Symposium on Robotics Research (ISRR)</em>, 2017
            <br>
            <em>Springer Proceedings in Advanced Robotics</em>, 2020
            <br>
            <a href="data/Yang2017ISRR.bib">bibtex</a> /
            <a href="https://www.youtube.com/watch?v=88TX3QWvITY">video</a>
            <br>
            <br>
            <a href="papers/rss18_workshop.pdf">
              <papertitle>Attack-Resilient Map-based Localization</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>Workshop of Adversarial Robotics at RSS 2018</em>
            <br>
            <a href="https://rislab.github.io/rss2018website/program/workshops/sat02/">website</a>
            <br>
            <p></p>
            <p>Weighted maximum correntropy criterion (MCC)-based EKF.
              <br>
              Secure Estimation (SE)-EKF with attack detection.
              <br>
              Intensive Monte-Carlo simulations and experiments on real world datasets.
            </p>
          </td>
        </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/iros2017_nullspace1.png" alt="Nullspace" width="300" height="240">
          </td>
          <td width="75%" valign="middle">
            <a href="papers/2017_iros_null.pdf">
              <papertitle>Null-Space-based Marginalization: Analysis and Algorithm</papertitle>
            </a>
            <br>
            <strong>Yulin Yang</strong>, <a href="https://sites.udel.edu/robot/people/">James Maley</a>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
            <br>
            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2017
            <br>
            <a href="data/Yang2017IROS_nullspace.bib">bibtex</a>
            <br>
            <p></p>
            <p>Null-space is equivalent to Schur complement with i.i.d. noise.
              <br>
              Time complexity analysis for Null-space and Schur complement.
              <br>
              Analytic null-space for MSCKF.
            </p>
          </td>
        </tr>



          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icra2017_ains.png" alt="AINS" width="300" height="220">
            </td>
            <td width="75%" valign="middle">
              <a href="papers/2017_icra_ains.pdf">
                <papertitle>Acoustic Inertial Underwater Navigation</papertitle>
              </a>
              <br>
              <strong>Yulin Yang</strong>, <a href="https://udel.edu/~ghuang/">Guoquan(Paul) Huang</a>
              <br>
              <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2017
              <br>
              <a href="data/Yang2017ICRA_AINS.bib">bibtex</a>
              <br>
              <p></p>
              <p>2D imaging sonar + IMU for underwater navigation.
                <br>
                Degenerate motion analysis for feature triangulation with sonar.
                <br>
                Online calibration between sonar and IMU.
              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Special thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the website's <a href="https://github.com/yangyulin/yangyulin.github.io">source code</a>. Feel free to use as well as contribute to it.
<!--                If you like, you can add a star to Job Barron's <a href="https://jonbarron.info/">personal page</a>.-->
<!--                <br>-->
<!--                <a href="https://clustrmaps.com/site/1bhsk"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=SmVNKAru4SRtedjTqTTFYIJmNGoHTrBK5VOIsscudyM&cl=ffffff" /></a>-->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:25%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:25px;width:25%;vertical-align:middle">
            <p style="text-align:center;font-size:small;">
<!--              <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=tt&d=SmVNKAru4SRtedjTqTTFYIJmNGoHTrBK5VOIsscudyM'></script>-->
              <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=SmVNKAru4SRtedjTqTTFYIJmNGoHTrBK5VOIsscudyM'></script>
              <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=GBSsEzAYyt4c8PKMCuVFdjM_Lwlz1U7drURBMMaLC60"></script>
            </p>
          </td>
        </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
